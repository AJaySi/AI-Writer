â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ URL                  â”‚ Title                â”‚ Published Date   â”‚ Summary                                                      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ https://www.analytic â”‚ Using Llamafiles to  â”‚ 2024-01-18       â”‚ The article discusses Llamafiles, which simplify the process â”‚
â”‚ svidhya.com/blog/202 â”‚ Simplify LLM         â”‚                  â”‚ of running Large Language Models (LLMs) on consumer          â”‚
â”‚ 4/01/using-          â”‚ Execution            â”‚                  â”‚ hardware. Traditionally, running LLMs involved downloading   â”‚
â”‚ llamafiles-to-       â”‚                      â”‚                  â”‚ third-party software, creating Python environments, and      â”‚
â”‚ simplify-llm-        â”‚                      â”‚                  â”‚ writing code. Llamafiles address these challenges by         â”‚
â”‚ execution/           â”‚                      â”‚                  â”‚ enabling users to download and run LLMs as single-file       â”‚
â”‚                      â”‚                      â”‚                  â”‚ executables. Additionally, the article explains the concept  â”‚
â”‚                      â”‚                      â”‚                  â”‚ of Llamafiles, including its benefits and limitations, as    â”‚
â”‚                      â”‚                      â”‚                  â”‚ well as how to create Llamafiles from quantized LLMs.        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ https://levelup.gitc â”‚ Live Indexing for    â”‚ 2024-01-08       â”‚ - Most AI systems, including LLMs, struggle to process and   â”‚
â”‚ onnected.com/live-   â”‚ RAG: A Guide For     â”‚                  â”‚ answer questions from PDFs due to their complex information. â”‚
â”‚ indexing-for-rag-a-  â”‚ Real-Time Indexing   â”‚                  â”‚ - RAG frameworks and Large Language Models (LLMs) have       â”‚
â”‚ guide-for-real-time- â”‚ Using LlamaIndex and â”‚                  â”‚ enabled the creation of full-stack applications for          â”‚
â”‚ indexing-using-      â”‚ AWS                  â”‚                  â”‚ interacting with PDFs. - LlamaIndex is provided as an        â”‚
â”‚ llamaindex-and-aws-5 â”‚                      â”‚                  â”‚ example of a RAG framework that allows users to create chat  â”‚
â”‚ 1353083ace4?gi=472c9 â”‚                      â”‚                  â”‚ applications for interacting with PDFs with just a few lines â”‚
â”‚ 89ddb71&source=rss   â”‚                      â”‚                  â”‚ of code. - The article also discusses additional challenges  â”‚
â”‚ ----5517fd7b58a6---4 â”‚                      â”‚                  â”‚ for AI engineers in creating enterprise-grade RAG            â”‚
â”‚                      â”‚                      â”‚                  â”‚ applications such as re-indexing and live updates.           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ https://tech.dentsus â”‚ LlamaIndexã‚’ä½¿ã£ã¦ãƒ­ â”‚ 2024-01-22       â”‚ This webpage discusses how to implement Retrieval-Augmented  â”‚
â”‚ oken.com/entry/2024/ â”‚ ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§RAGã‚’å®Ÿ  â”‚                  â”‚ Generation (RAG) using the LlamaIndex library in a local     â”‚
â”‚ 01/22/LlamaIndex%E3% â”‚ è¡Œã™ã‚‹æ–¹æ³•           â”‚                  â”‚ environment. The goal is to leverage Large Language Models   â”‚
â”‚ 82%92%E4%BD%BF%E3%81 â”‚                      â”‚                  â”‚ (LLMs) like ChatGPT while addressing limitations such as     â”‚
â”‚ %A3%E3%81%A6%E3%83%A â”‚                      â”‚                  â”‚ data confidentiality and restricted internet access. The     â”‚
â”‚ D%E3%83%BC%E3%82%AB% â”‚                      â”‚                  â”‚ article highlights the benefits of using a local setup for   â”‚
â”‚ E3%83%AB%E7%92%B0%E5 â”‚                      â”‚                  â”‚ LLM applications and explains why the LlamaIndex framework   â”‚
â”‚ %A2%83%E3%81%A7RAG%E â”‚                      â”‚                  â”‚ is suitable for this purpose. The author provides detailed   â”‚
â”‚ 3%82%92%E5%AE%9F%E8% â”‚                      â”‚                  â”‚ instructions on setting up the environment, including        â”‚
â”‚ A1%8C%E3%81%99%E3%82 â”‚                      â”‚                  â”‚ installing necessary software and configuring a development  â”‚
â”‚ %8B%E6%96%B9%E6%B3%9 â”‚                      â”‚                  â”‚ container using Docker. Furthermore, the article guides      â”‚
â”‚ 5                    â”‚                      â”‚                  â”‚ readers through the process of loading data, initializing    â”‚
â”‚                      â”‚                      â”‚                  â”‚ LLM and embedding models, and implementing RAG using Python  â”‚
â”‚                      â”‚                      â”‚                  â”‚ code. It also includes a sample implementation of a chat     â”‚
â”‚                      â”‚                      â”‚                  â”‚ system that leverages RAG to answer questions based on a     â”‚
â”‚                      â”‚                      â”‚                  â”‚ provided text document. The author discusses the challenges  â”‚
â”‚                      â”‚                      â”‚                  â”‚ faced during implementation and suggests potential           â”‚
â”‚                      â”‚                      â”‚                  â”‚ improvements, such as optimizing performance by reducing     â”‚
â”‚                      â”‚                      â”‚                  â”‚ context information and leveraging more powerful hardware.   â”‚
â”‚                      â”‚                      â”‚                  â”‚ The article concludes by encouraging readers to experiment   â”‚
â”‚                      â”‚                      â”‚                  â”‚ with RAG and emphasizing the potential of this technology to â”‚
â”‚                      â”‚                      â”‚                  â”‚ create useful applications.                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ https://dev.to/lgram â”‚ Create Your Own      â”‚ 2024-01-13       â”‚ This blog post provides a detailed guide on how to build a   â”‚
â”‚ mel/create-your-own- â”‚ Local Chatbot with   â”‚                  â”‚ local chatbot using several technologies. Here's a summary:  â”‚
â”‚ local-chatbot-with-  â”‚ Next.js, Llama.cpp,  â”‚                  â”‚ Objective of the blog post: - Build a chatbot that runs on   â”‚
â”‚ nextjs-llamacpp-and- â”‚ and ModelFusion      â”‚                  â”‚ your computer using Next.js, Llama.cpp, and ModelFusion. -   â”‚
â”‚ modelfusion-461j     â”‚                      â”‚                  â”‚ Use the OpenHermes 2.5 Mistral LLM (large language model)    â”‚
â”‚                      â”‚                      â”‚                  â”‚ for natural language interaction. - Employ the Vercel AI SDK â”‚
â”‚                      â”‚                      â”‚                  â”‚ for stream forwarding and rendering. - Integrate the         â”‚
â”‚                      â”‚                      â”‚                  â”‚ Llama.cpp language model with the Vercel AI SDK through      â”‚
â”‚                      â”‚                      â”‚                  â”‚ ModelFusion.  Necessary Steps: 1. Setup Llama.cpp:    a)     â”‚
â”‚                      â”‚                      â”‚                  â”‚ Clone the repository.    b) Build Llama.cpp: Linux/Mac users â”‚
â”‚                      â”‚                      â”‚                  â”‚ can run "make", Windows users can follow the instructions    â”‚
â”‚                      â”‚                      â”‚                  â”‚ provided.    c) Download the OpenHermes 2.5 Mistral GGUF     â”‚
â”‚                      â”‚                      â”‚                  â”‚ model from HuggingFace and move it into the Llama.cpp        â”‚
â”‚                      â”‚                      â”‚                  â”‚ repository's "models/" directory.    d) Start the Llama.cpp  â”‚
â”‚                      â”‚                      â”‚                  â”‚ server to enable the integration of the model into the       â”‚
â”‚                      â”‚                      â”‚                  â”‚ chatbot.  2. Create a Next.js Project:    a) Create a new    â”‚
â”‚                      â”‚                      â”‚                  â”‚ Next.js project using "npx create-next-app@latest llamacpp-  â”‚
â”‚                      â”‚                      â”‚                  â”‚ nextjs-chatbot".    b) Configure the project with preferred  â”‚
â”‚                      â”‚                      â”‚                  â”‚ settings, including TypeScript, ESLint, Tailwind CSS, and    â”‚
â”‚                      â”‚                      â”‚                  â”‚ App Router.  3. Install Required Libraries:    a) Install    â”‚
â”‚                      â”‚                      â”‚                  â”‚ libraries such as Vercel AI SDK, ModelFusion, and            â”‚
â”‚                      â”‚                      â”‚                  â”‚ ModelFusion Vercel AI SDK Integration.  4. Creating an API   â”‚
â”‚                      â”‚                      â”‚                  â”‚ Route for the Chatbot:    a) In the 'api/chat/' directory,   â”‚
â”‚                      â”‚                      â”‚                  â”‚ create 'route.ts' for handling chat interactions.    b)      â”‚
â”‚                      â”‚                      â”‚                  â”‚ Import relevant modules and initialize a ModelFusion text    â”‚
â”‚                      â”‚                      â”‚                  â”‚ generation model.    c) Send the API request, process the    â”‚
â”‚                      â”‚                      â”‚                  â”‚ response, and generate a streaming response using            â”‚
â”‚                      â”‚                      â”‚                  â”‚ ModelFusion to access the Llama.cpp chat API.  5. Adding the â”‚
â”‚                      â”‚                      â”‚                  â”‚ Chat Interface:    a) Establish a chat page, 'page.tsx' to   â”‚
â”‚                      â”‚                      â”‚                  â”‚ display the chatbot and use the 'useChat' hook from the      â”‚
â”‚                      â”‚                      â”‚                  â”‚ Vercel AI SDK.    b) Clean up the global styles for better   â”‚
â”‚                      â”‚                      â”‚                  â”‚ UI presentation.  6. Running the Chatbot Application:    a)  â”‚
â”‚                      â”‚                      â”‚                  â”‚ Launch the development server with "npm run dev".    b) In a â”‚
â”‚                      â”‚                      â”‚                  â”‚ browser, navigate to "http://localhost:3000" to interact     â”‚
â”‚                      â”‚                      â”‚                  â”‚ with the chatbot.  Conclusion: The tutorial provides a step- â”‚
â”‚                      â”‚                      â”‚                  â”‚ by-step guide to set up a local chatbot, enabling users to   â”‚
â”‚                      â”‚                      â”‚                  â”‚ explore AI and natural language processing.                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ https://akash-mathur â”‚ Advanced RAG: Query  â”‚ 2024-01-18       â”‚ Welcome to the Advanced RAG Learning Series. This article    â”‚
â”‚ .medium.com/advanced â”‚ Augmentation for     â”‚                  â”‚ series explores advanced techniques to heighten              â”‚
â”‚ -rag-query-          â”‚ Next-Level Search    â”‚                  â”‚ understanding and expertise in Retriever-Augmented           â”‚
â”‚ augmentation-for-    â”‚ using LlamaIndexğŸ¦™   â”‚                  â”‚ Generation (RAG) applications.  Key concepts covered include â”‚
â”‚ next-level-search-   â”‚                      â”‚                  â”‚ optimizing retrieval with extra context and metadata,        â”‚
â”‚ using-llamaindex-d36 â”‚                      â”‚                  â”‚ improving retrieval efficiency via rerankers, and enhancing  â”‚
â”‚ 2fed7ecc3            â”‚                      â”‚                  â”‚ query augmentation.  The focus is on query transformations   â”‚
â”‚                      â”‚                      â”‚                  â”‚ which bridge user prompts and relevant information in vast   â”‚
â”‚                      â”‚                      â”‚                  â”‚ databases, particularly to address the challenge of          â”‚
â”‚                      â”‚                      â”‚                  â”‚ retrieval misalignment.  Five powerful query transformation  â”‚
â”‚                      â”‚                      â”‚                  â”‚ techniques are explored, addressing the need to adapt to     â”‚
â”‚                      â”‚                      â”‚                  â”‚ LLMs' comprehension and generation capabilities. The         â”‚
â”‚                      â”‚                      â”‚                  â”‚ techniques explored are:  - Hypothetical Document Embeddings â”‚
â”‚                      â”‚                      â”‚                  â”‚ (HyDE), which creates a hypothetical answer document and     â”‚
â”‚                      â”‚                      â”‚                  â”‚ encodes it to retrieve relevant documents. - Sub-Question    â”‚
â”‚                      â”‚                      â”‚                  â”‚ Query Engine, which decomposes complex queries into sub-     â”‚
â”‚                      â”‚                      â”‚                  â”‚ questions and retrieves results from dedicated data sources. â”‚
â”‚                      â”‚                      â”‚                  â”‚ - Router Query Engine, which selects the most appropriate    â”‚
â”‚                      â”‚                      â”‚                  â”‚ query engine based on user queries and metadata. - Single-   â”‚
â”‚                      â”‚                      â”‚                  â”‚ Step Query Decomposition, which breaks down complex          â”‚
â”‚                      â”‚                      â”‚                  â”‚ questions into simpler sub-queries for focused information   â”‚
â”‚                      â”‚                      â”‚                  â”‚ extraction. - Multi-Step Query Decomposition, which employs  â”‚
â”‚                      â”‚                      â”‚                  â”‚ a self-ask method to iteratively explore knowledge and       â”‚
â”‚                      â”‚                      â”‚                  â”‚ uncover hidden connections among facts.  The article         â”‚
â”‚                      â”‚                      â”‚                  â”‚ provides code examples and GitHub links to assist in         â”‚
â”‚                      â”‚                      â”‚                  â”‚ practical implementation. It also highlights the ongoing     â”‚
â”‚                      â”‚                      â”‚                  â”‚ developments and potential future directions in query        â”‚
â”‚                      â”‚                      â”‚                  â”‚ augmentation research.                                       â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›


