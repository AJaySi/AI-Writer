"""
Integration Test for 12-Step Prompt Chaining Framework

This script tests the complete integration with real AI services and database connections.
"""

import asyncio
import sys
import os
import json
from datetime import datetime
from typing import Dict, Any

# Add the current directory to Python path
sys.path.append(os.path.dirname(__file__))

# Check if we can import the real services
def check_service_availability():
    """Check which services are available."""
    services_status = {
        "prompt_chaining": False,
        "ai_engine": False,
        "keyword_researcher": False,
        "competitor_analyzer": False,
        "onboarding_service": False,
        "ai_analytics": False,
        "content_planning_db": False
    }
    
    try:
        from calendar_generation_datasource_framework.prompt_chaining import PromptChainOrchestrator
        services_status["prompt_chaining"] = True
        print("‚úÖ Prompt Chaining Framework available")
    except ImportError as e:
        print(f"‚ùå Prompt Chaining Framework not available: {e}")
    
    try:
        from content_gap_analyzer.ai_engine_service import AIEngineService
        services_status["ai_engine"] = True
        print("‚úÖ AI Engine Service available")
    except ImportError as e:
        print(f"‚ö†Ô∏è AI Engine Service not available: {e}")
    
    try:
        from content_gap_analyzer.keyword_researcher import KeywordResearcher
        services_status["keyword_researcher"] = True
        print("‚úÖ Keyword Researcher available")
    except ImportError as e:
        print(f"‚ö†Ô∏è Keyword Researcher not available: {e}")
    
    try:
        from content_gap_analyzer.competitor_analyzer import CompetitorAnalyzer
        services_status["competitor_analyzer"] = True
        print("‚úÖ Competitor Analyzer available")
    except ImportError as e:
        print(f"‚ö†Ô∏è Competitor Analyzer not available: {e}")
    
    try:
        from onboarding_data_service import OnboardingDataService
        services_status["onboarding_service"] = True
        print("‚úÖ Onboarding Data Service available")
    except ImportError as e:
        print(f"‚ö†Ô∏è Onboarding Data Service not available: {e}")
    
    try:
        from ai_analytics_service import AIAnalyticsService
        services_status["ai_analytics"] = True
        print("‚úÖ AI Analytics Service available")
    except ImportError as e:
        print(f"‚ö†Ô∏è AI Analytics Service not available: {e}")
    
    try:
        from content_planning_db import ContentPlanningDBService
        services_status["content_planning_db"] = True
        print("‚úÖ Content Planning DB Service available")
    except ImportError as e:
        print(f"‚ö†Ô∏è Content Planning DB Service not available: {e}")
    
    return services_status

async def test_real_ai_services():
    """Test real AI services connectivity."""
    print("ü§ñ Testing Real AI Services")
    print("=" * 40)
    
    success_count = 0
    total_tests = 0
    
    # Test AI Engine Service
    try:
        from content_gap_analyzer.ai_engine_service import AIEngineService
        ai_engine = AIEngineService()
        
        print("üéØ Testing AI Engine Service...")
        
        # Test strategic insights generation
        total_tests += 1
        try:
            result = await ai_engine.generate_strategic_insights(
                strategy_data={"content_pillars": ["AI", "Technology"]},
                onboarding_data={"website_analysis": {"industry": "technology"}},
                industry="technology",
                business_size="sme"
            )
            if result and isinstance(result, dict):
                print(f"‚úÖ Strategic insights generation: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Strategic insights generation: Empty result")
        except Exception as e:
            print(f"‚ùå Strategic insights generation: {str(e)}")
        
        # Test content gap analysis
        total_tests += 1
        try:
            result = await ai_engine.analyze_content_gaps(
                gap_data={"content_gaps": ["Blog posts", "Video content"]},
                keyword_analysis={"high_value_keywords": ["AI", "technology"]},
                competitor_analysis={"insights": {"competitors": ["comp1"]}},
                industry="technology"
            )
            if result and isinstance(result, dict):
                print(f"‚úÖ Content gap analysis: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Content gap analysis: Empty result")
        except Exception as e:
            print(f"‚ùå Content gap analysis: {str(e)}")
        
        # Test audience behavior analysis
        total_tests += 1
        try:
            result = await ai_engine.analyze_audience_behavior(
                onboarding_data={"website_analysis": {"target_audience": ["developers"]}},
                strategy_data={"target_audience": {"demographics": {"age": "25-35"}}},
                industry="technology",
                business_size="sme"
            )
            if result and isinstance(result, dict):
                print(f"‚úÖ Audience behavior analysis: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Audience behavior analysis: Empty result")
        except Exception as e:
            print(f"‚ùå Audience behavior analysis: {str(e)}")
        
    except ImportError:
        print("‚ùå AI Engine Service not available for testing")
    
    # Test Keyword Researcher
    try:
        from content_gap_analyzer.keyword_researcher import KeywordResearcher
        keyword_researcher = KeywordResearcher()
        
        print("\nüîç Testing Keyword Researcher...")
        
        # Test keyword analysis
        total_tests += 1
        try:
            result = await keyword_researcher.analyze_keywords(
                target_keywords=["AI", "technology", "automation"],
                industry="technology"
            )
            if result and isinstance(result, dict):
                print(f"‚úÖ Keyword analysis: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Keyword analysis: Empty result")
        except Exception as e:
            print(f"‚ùå Keyword analysis: {str(e)}")
        
        # Test trending topics
        total_tests += 1
        try:
            result = await keyword_researcher.get_trending_topics(
                industry="technology"
            )
            if result and isinstance(result, list):
                print(f"‚úÖ Trending topics: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Trending topics: Empty result")
        except Exception as e:
            print(f"‚ùå Trending topics: {str(e)}")
        
    except ImportError:
        print("‚ùå Keyword Researcher not available for testing")
    
    # Test Competitor Analyzer
    try:
        from content_gap_analyzer.competitor_analyzer import CompetitorAnalyzer
        competitor_analyzer = CompetitorAnalyzer()
        
        print("\nüè¢ Testing Competitor Analyzer...")
        
        # Test competitor analysis
        total_tests += 1
        try:
            result = await competitor_analyzer.analyze_competitors(
                competitor_urls=["https://example.com", "https://competitor.com"],
                industry="technology"
            )
            if result and isinstance(result, dict):
                print(f"‚úÖ Competitor analysis: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Competitor analysis: Empty result")
        except Exception as e:
            print(f"‚ùå Competitor analysis: {str(e)}")
        
    except ImportError:
        print("‚ùå Competitor Analyzer not available for testing")
    
    print(f"\nüìä AI Services Test Summary: {success_count}/{total_tests} tests passed")
    return success_count, total_tests

async def test_data_services():
    """Test data services connectivity."""
    print("\nüíæ Testing Data Services")
    print("=" * 40)
    
    success_count = 0
    total_tests = 0
    
    # Test Onboarding Data Service
    try:
        from onboarding_data_service import OnboardingDataService
        onboarding_service = OnboardingDataService()
        
        print("üë§ Testing Onboarding Data Service...")
        
        # Test get personalized inputs
        total_tests += 1
        try:
            result = onboarding_service.get_personalized_ai_inputs(1)
            if result and isinstance(result, dict):
                print(f"‚úÖ Get personalized AI inputs: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Get personalized AI inputs: Empty result")
        except Exception as e:
            print(f"‚ùå Get personalized AI inputs: {str(e)}")
        
    except ImportError:
        print("‚ùå Onboarding Data Service not available for testing")
    
    # Test AI Analytics Service
    try:
        from ai_analytics_service import AIAnalyticsService
        ai_analytics = AIAnalyticsService()
        
        print("\nüß† Testing AI Analytics Service...")
        
        # Test strategic intelligence generation
        total_tests += 1
        try:
            result = await ai_analytics.generate_strategic_intelligence(1)
            if result and isinstance(result, dict):
                print(f"‚úÖ Strategic intelligence generation: SUCCESS")
                success_count += 1
            else:
                print(f"‚ö†Ô∏è Strategic intelligence generation: Empty result")
        except Exception as e:
            print(f"‚ùå Strategic intelligence generation: {str(e)}")
        
    except ImportError:
        print("‚ùå AI Analytics Service not available for testing")
    
    # Test Content Planning DB Service
    try:
        from content_planning_db import ContentPlanningDBService
        # Note: This would require proper database session injection
        print("\nüóÉÔ∏è Testing Content Planning DB Service...")
        print("‚ÑπÔ∏è Database service requires proper session injection - skipping direct test")
        
    except ImportError:
        print("‚ùå Content Planning DB Service not available for testing")
    
    print(f"\nüìä Data Services Test Summary: {success_count}/{total_tests} tests passed")
    return success_count, total_tests

async def test_12_step_framework_integration():
    """Test the 12-step framework with real service integration."""
    print("\nüöÄ Testing 12-Step Framework Integration")
    print("=" * 50)
    
    try:
        from calendar_generation_datasource_framework.prompt_chaining import PromptChainOrchestrator
        
        # Initialize orchestrator
        print("üìã Initializing Prompt Chain Orchestrator...")
        orchestrator = PromptChainOrchestrator()
        
        # Check health status
        health_status = await orchestrator.get_health_status()
        print(f"‚úÖ Framework Health: {health_status['status']}")
        print(f"üìä Steps Configured: {health_status['steps_configured']}")
        print(f"üèóÔ∏è Phases Configured: {health_status['phases_configured']}")
        
        # Test calendar generation with real services
        print("\nüéØ Testing Calendar Generation...")
        
        try:
            result = await orchestrator.generate_calendar(
                user_id=1,
                strategy_id=1,
                calendar_type="monthly",
                industry="technology",
                business_size="sme"
            )
            
            print("‚úÖ Calendar generation completed!")
            print(f"üìã Result keys: {list(result.keys())}")
            print(f"‚è±Ô∏è Processing time: {result.get('processing_time', 0):.2f}s")
            print(f"üéØ Framework version: {result.get('framework_version', 'unknown')}")
            print(f"üìä Status: {result.get('status', 'unknown')}")
            
            # Validate result structure
            required_fields = [
                'user_id', 'strategy_id', 'processing_time', 'generated_at',
                'framework_version', 'status'
            ]
            
            missing_fields = [field for field in required_fields if field not in result]
            if missing_fields:
                print(f"‚ö†Ô∏è Missing required fields: {missing_fields}")
            else:
                print("‚úÖ All required fields present")
            
            # Check for calendar content
            calendar_fields = [
                'daily_schedule', 'weekly_themes', 'content_recommendations',
                'optimal_timing', 'performance_predictions', 'trending_topics'
            ]
            
            present_fields = [field for field in calendar_fields if field in result and result[field]]
            print(f"üìã Calendar content fields present: {len(present_fields)}/{len(calendar_fields)}")
            
            return True, result
            
        except Exception as e:
            print(f"‚ùå Calendar generation failed: {str(e)}")
            return False, None
        
    except ImportError as e:
        print(f"‚ùå 12-Step Framework not available: {e}")
        return False, None

async def test_phase1_steps_integration():
    """Test Phase 1 steps with real service integration."""
    print("\nüéØ Testing Phase 1 Steps Integration")
    print("=" * 50)
    
    try:
        from calendar_generation_datasource_framework.prompt_chaining.steps.phase1_steps import (
            ContentStrategyAnalysisStep,
            GapAnalysisStep,
            AudiencePlatformStrategyStep
        )
        
        # Test context
        context = {
            "user_id": 1,
            "strategy_id": 1,
            "calendar_type": "monthly",
            "industry": "technology",
            "business_size": "sme",
            "user_data": {
                "strategy_data": {
                    "content_pillars": ["AI", "Technology", "Innovation"],
                    "target_audience": {"demographics": {"age": "25-35", "location": "US"}},
                    "business_goals": ["Increase brand awareness", "Generate leads"],
                    "success_metrics": ["Website traffic", "Social engagement"]
                },
                "onboarding_data": {
                    "website_analysis": {"industry": "technology", "target_audience": ["developers"]},
                    "competitor_analysis": {"top_performers": ["competitor1", "competitor2"]},
                    "keyword_analysis": {"high_value_keywords": ["AI", "automation"]}
                },
                "gap_analysis": {
                    "content_gaps": ["Video content", "Interactive demos"],
                    "keyword_opportunities": ["machine learning", "artificial intelligence"]
                },
                "performance_data": {
                    "engagement_metrics": {"average_engagement": 0.05},
                    "best_performing_content": ["How-to guides", "Industry insights"]
                },
                "competitor_data": {
                    "competitor_urls": ["https://competitor1.com", "https://competitor2.com"]
                }
            },
            "step_results": {},
            "quality_scores": {},
            "current_step": 0,
            "phase": "initialization"
        }
        
        phase1_results = {}
        
        # Test Step 1: Content Strategy Analysis
        print("üéØ Testing Step 1: Content Strategy Analysis")
        try:
            step1 = ContentStrategyAnalysisStep()
            result1 = await step1.run(context)
            phase1_results["step_01"] = result1
            
            print(f"‚úÖ Step 1 Status: {result1.get('status', 'unknown')}")
            print(f"üìä Step 1 Quality: {result1.get('quality_score', 0.0):.2f}")
            print(f"‚è±Ô∏è Step 1 Time: {result1.get('execution_time', 0.0):.2f}s")
            
        except Exception as e:
            print(f"‚ùå Step 1 failed: {str(e)}")
        
        # Test Step 2: Gap Analysis & Opportunity Identification
        print("\nüéØ Testing Step 2: Gap Analysis & Opportunity Identification")
        try:
            step2 = GapAnalysisStep()
            result2 = await step2.run(context)
            phase1_results["step_02"] = result2
            
            print(f"‚úÖ Step 2 Status: {result2.get('status', 'unknown')}")
            print(f"üìä Step 2 Quality: {result2.get('quality_score', 0.0):.2f}")
            print(f"‚è±Ô∏è Step 2 Time: {result2.get('execution_time', 0.0):.2f}s")
            
        except Exception as e:
            print(f"‚ùå Step 2 failed: {str(e)}")
        
        # Test Step 3: Audience & Platform Strategy
        print("\nüéØ Testing Step 3: Audience & Platform Strategy")
        try:
            step3 = AudiencePlatformStrategyStep()
            result3 = await step3.run(context)
            phase1_results["step_03"] = result3
            
            print(f"‚úÖ Step 3 Status: {result3.get('status', 'unknown')}")
            print(f"üìä Step 3 Quality: {result3.get('quality_score', 0.0):.2f}")
            print(f"‚è±Ô∏è Step 3 Time: {result3.get('execution_time', 0.0):.2f}s")
            
        except Exception as e:
            print(f"‚ùå Step 3 failed: {str(e)}")
        
        # Calculate overall Phase 1 metrics
        completed_steps = len([r for r in phase1_results.values() if r.get('status') == 'completed'])
        total_quality = sum(r.get('quality_score', 0.0) for r in phase1_results.values())
        avg_quality = total_quality / len(phase1_results) if phase1_results else 0.0
        total_time = sum(r.get('execution_time', 0.0) for r in phase1_results.values())
        
        print(f"\nüìã Phase 1 Integration Summary")
        print("=" * 40)
        print(f"‚úÖ Completed Steps: {completed_steps}/3")
        print(f"üìä Average Quality: {avg_quality:.2f}")
        print(f"‚è±Ô∏è Total Time: {total_time:.2f}s")
        
        return completed_steps == 3, phase1_results
        
    except ImportError as e:
        print(f"‚ùå Phase 1 steps not available: {e}")
        return False, {}

async def generate_integration_report(
    services_status: Dict[str, bool],
    ai_services_result: tuple,
    data_services_result: tuple,
    framework_result: tuple,
    phase1_result: tuple
):
    """Generate comprehensive integration test report."""
    print("\nüìã Integration Test Report")
    print("=" * 60)
    
    # Service availability
    available_services = sum(services_status.values())
    total_services = len(services_status)
    print(f"üîß Service Availability: {available_services}/{total_services}")
    
    # AI services
    ai_success, ai_total = ai_services_result
    print(f"ü§ñ AI Services: {ai_success}/{ai_total} tests passed")
    
    # Data services
    data_success, data_total = data_services_result
    print(f"üíæ Data Services: {data_success}/{data_total} tests passed")
    
    # Framework integration
    framework_success, framework_data = framework_result
    print(f"üöÄ Framework Integration: {'SUCCESS' if framework_success else 'FAILED'}")
    
    # Phase 1 integration
    phase1_success, phase1_data = phase1_result
    print(f"üéØ Phase 1 Integration: {'SUCCESS' if phase1_success else 'FAILED'}")
    
    # Overall assessment
    total_tests = ai_total + data_total + (1 if framework_success else 0) + (3 if phase1_success else 0)
    total_success = ai_success + data_success + (1 if framework_success else 0) + (3 if phase1_success else len(phase1_data))
    
    print(f"\nüéâ Overall Integration: {total_success}/{total_tests} ({total_success/total_tests*100:.1f}%)")
    
    # Recommendations
    print(f"\nüìù Recommendations:")
    if available_services < total_services:
        print("  ‚Ä¢ Set up missing services for full integration")
    if ai_success < ai_total:
        print("  ‚Ä¢ Check AI service configurations and API keys")
    if data_success < data_total:
        print("  ‚Ä¢ Verify database connections and service dependencies")
    if not framework_success:
        print("  ‚Ä¢ Debug framework integration issues")
    if not phase1_success:
        print("  ‚Ä¢ Review Phase 1 step implementations")
    
    if total_success == total_tests:
        print("  ‚úÖ All systems operational - ready for production!")
    
    # Save detailed report
    report = {
        "timestamp": datetime.now().isoformat(),
        "service_availability": services_status,
        "ai_services": {"success": ai_success, "total": ai_total},
        "data_services": {"success": data_success, "total": data_total},
        "framework_integration": {"success": framework_success},
        "phase1_integration": {"success": phase1_success, "results": phase1_data},
        "overall": {"success": total_success, "total": total_tests, "percentage": total_success/total_tests*100}
    }
    
    with open("integration_test_report.json", "w") as f:
        json.dump(report, f, indent=2, default=str)
    
    print(f"\nüíæ Detailed report saved to: integration_test_report.json")

async def main():
    """Main integration test function."""
    print("üß™ 12-Step Framework Integration Test Suite")
    print("=" * 60)
    print(f"üïí Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Check service availability
    print("\nüîç Checking Service Availability...")
    services_status = check_service_availability()
    
    # Test AI services
    ai_services_result = await test_real_ai_services()
    
    # Test data services
    data_services_result = await test_data_services()
    
    # Test 12-step framework integration
    framework_result = await test_12_step_framework_integration()
    
    # Test Phase 1 steps integration
    phase1_result = await test_phase1_steps_integration()
    
    # Generate comprehensive report
    await generate_integration_report(
        services_status,
        ai_services_result,
        data_services_result,
        framework_result,
        phase1_result
    )
    
    print(f"\nüèÅ Integration test completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    asyncio.run(main())
